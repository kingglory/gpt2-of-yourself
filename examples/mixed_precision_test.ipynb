{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "demo-fp16.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "524dc030edf24fd294390f9da5a360e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1574aa76516e43b9b7772615c2a679f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f6934ca621f4bf4a87272798721ff8d",
              "IPY_MODEL_c0b1c0b0c4d8424bbca3471347c7fdaa"
            ]
          }
        },
        "1574aa76516e43b9b7772615c2a679f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f6934ca621f4bf4a87272798721ff8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff848af2f9e249919192db4f81210802",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a49942edd1514293a65af568a3d8227c"
          }
        },
        "c0b1c0b0c4d8424bbca3471347c7fdaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_58cd1ceac3da46e79928efd3b6af8a3d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 9.13MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c1f67bac76848598762a0da1fff0032"
          }
        },
        "ff848af2f9e249919192db4f81210802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a49942edd1514293a65af568a3d8227c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58cd1ceac3da46e79928efd3b6af8a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c1f67bac76848598762a0da1fff0032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7010786313364b3f80713de08b571528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8276e2dff64f4a0aaf68a6f7ad9a573b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_04a2a76ac10545c9801420c353dd33d8",
              "IPY_MODEL_b74984ac0551484c95a0c6381f664e88"
            ]
          }
        },
        "8276e2dff64f4a0aaf68a6f7ad9a573b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04a2a76ac10545c9801420c353dd33d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9faaade8dbdd4115b4b5b0b354d2b657",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c00d7cf2a9f4c389a045cffe8d3430d"
          }
        },
        "b74984ac0551484c95a0c6381f664e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad07e052ea2947219dadb7a1ee738b0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 4.23MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cc3926286d54a418f42f97967f7325c"
          }
        },
        "9faaade8dbdd4115b4b5b0b354d2b657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c00d7cf2a9f4c389a045cffe8d3430d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad07e052ea2947219dadb7a1ee738b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cc3926286d54a418f42f97967f7325c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5bGic4pR5Pm"
      },
      "source": [
        "!pip install transformers==4.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "524dc030edf24fd294390f9da5a360e0",
            "1574aa76516e43b9b7772615c2a679f1",
            "1f6934ca621f4bf4a87272798721ff8d",
            "c0b1c0b0c4d8424bbca3471347c7fdaa",
            "ff848af2f9e249919192db4f81210802",
            "a49942edd1514293a65af568a3d8227c",
            "58cd1ceac3da46e79928efd3b6af8a3d",
            "0c1f67bac76848598762a0da1fff0032",
            "7010786313364b3f80713de08b571528",
            "8276e2dff64f4a0aaf68a6f7ad9a573b",
            "04a2a76ac10545c9801420c353dd33d8",
            "b74984ac0551484c95a0c6381f664e88",
            "9faaade8dbdd4115b4b5b0b354d2b657",
            "2c00d7cf2a9f4c389a045cffe8d3430d",
            "ad07e052ea2947219dadb7a1ee738b0f",
            "7cc3926286d54a418f42f97967f7325c"
          ]
        },
        "id": "MoFW4TwYz5QN",
        "outputId": "2498de45-ec66-4c90-ff2f-975c411d93f0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
        "\n",
        "text = \"\"\"\n",
        "A SQUAT grey building of only thirty-four stories. Over the main entrance the\n",
        "words, CENTRAL LONDON HATCHERY AND CONDITIONING CENTRE,\n",
        "and, in a shield, the World State’s motto, COMMUNITY, IDENTITY, STABILITY.\n",
        "The enormous room on the ground floor faced towards the north. Cold for\n",
        "all the summer beyond the panes, for all the tropical heat of the room itself,\n",
        "a harsh thin light glared through the windows, hungrily seeking some draped\n",
        "lay figure, some pallid shape of academic goose-flesh, but finding only the glass\n",
        "and nickel and bleakly shining porcelain of a laboratory. Wintriness responded\n",
        "to wintriness. The overalls of the workers were white, their hands gloved with\n",
        "a pale corpse-coloured rubber. The light was frozen, dead, a ghost. Only from\n",
        "the yellow barrels of the microscopes did it borrow a certain rich and living\n",
        "substance, lying along the polished tubes like butter, streak after luscious streak\n",
        "in long recession down the work tables.\n",
        "“And this,” said the Director opening the door, “is the Fertilizing Room.”\n",
        "Bent over their instruments, three hundred Fertilizers were plunged, as the Director of Hatcheries and Conditioning entered the room, in the scarcely breathing silence, the absent-minded, soliloquizing hum or whistle, of absorbed\n",
        "concentration. A troop of newly arrived students, very young, pink and callow,\n",
        "followed nervously, rather abjectly, at the Director’s heels. Each of them carried\n",
        "a notebook, in which, whenever the great man spoke, he desperately scribbled.\n",
        "Straight from the horse’s mouth. It was a rare privilege. The D. H. C. for Central\n",
        "London always made a point of personally conducting his new students round\n",
        "the various departments.\n",
        "“Just to give you a general idea,” he would explain to them. For of course some\n",
        "sort of general idea they must have, if they were to do their work intelligentlythough as little of one, if they were to be good and happy members of society, as\n",
        "possible. For particulars, as every one knows, make for virture and happiness;\n",
        "generalities are intellectually necessary evils. Not philosophers but fretsawyers\n",
        "\"\"\" * 100\n",
        "\n",
        "tokenized_text = tokenizer.encode(text)\n",
        "\n",
        "examples = []\n",
        "block_size = 512\n",
        "for i in range(0, len(tokenized_text) - block_size + 1, block_size):  # Truncate in block of block_size\n",
        "    examples.append(tokenized_text[i:i + block_size])\n",
        "\n",
        "inputs, labels = [], []\n",
        "for ex in examples:\n",
        "    inputs.append(ex[:-1])\n",
        "    labels.append(ex[1:])\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
        "\n",
        "\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "524dc030edf24fd294390f9da5a360e0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7010786313364b3f80713de08b571528",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (51200 > 1024). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YthP1ab-R5Pr",
        "outputId": "eba49bf5-7109-491c-a216-c834d88eefc7"
      },
      "source": [
        "#@title works good without mixed_precision\n",
        "\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel, GPT2Config\n",
        "from tensorflow.keras.mixed_precision import experimental, global_policy\n",
        "\n",
        "current_policy = global_policy()\n",
        "print(f\"current_policy: {current_policy}\")\n",
        "\n",
        "config = GPT2Config(\n",
        "            vocab_size=tokenizer.vocab_size,\n",
        "            n_positions=512,\n",
        "            n_ctx=512,\n",
        "            n_embd=512,\n",
        "            n_layer=4,\n",
        "            n_head=4,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            use_cache=False,\n",
        "        )\n",
        "model = TFGPT2LMHeadModel(config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "model.compile(optimizer=optimizer, loss=[loss, *[None] * model.config.n_layer], metrics=[metric])\n",
        "model.fit(dataset, epochs=20)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current_policy: <PolicyV1 \"mixed_float16\", loss_scale=DynamicLossScale(current_loss_scale=32768.0, num_good_steps=0, initial_loss_scale=32768.0, increment_period=2000, multiplier=2.0)>\n",
            "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
            "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
            "\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "6/6 [==============================] - 18s 2s/step - loss: 10.5879 - accuracy: 0.0317\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 9.7930 - accuracy: 0.0772\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 9.4057 - accuracy: 0.0779\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 9.0126 - accuracy: 0.1084\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 8.5122 - accuracy: 0.2280\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 7.9687 - accuracy: 0.3677\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 7.4126 - accuracy: 0.4819\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 6.8892 - accuracy: 0.5841\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 6.4235 - accuracy: 0.6719\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 6.0039 - accuracy: 0.7604\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 5.6319 - accuracy: 0.8393\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 5.2969 - accuracy: 0.8953\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 4.9904 - accuracy: 0.9289\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 4.7078 - accuracy: 0.9534\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 4.4475 - accuracy: 0.9708\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 4.2041 - accuracy: 0.9823\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 3.9783 - accuracy: 0.9875\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 3.7639 - accuracy: 0.9924\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 3.5620 - accuracy: 0.9947\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 3.3701 - accuracy: 0.9966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe92dba1a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAeMx5gubydW",
        "outputId": "4098f674-bf82-4dc0-c5ff-54b88810790e"
      },
      "source": [
        "#@title current mixed_precision with ad bad result\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel, GPT2Config\n",
        "from tensorflow.keras.mixed_precision import experimental, global_policy\n",
        "\n",
        "policy = experimental.Policy('mixed_float16')\n",
        "experimental.set_policy(policy)\n",
        "current_policy = global_policy()\n",
        "print(f\"current_policy: {current_policy}\")\n",
        "\n",
        "\n",
        "config = GPT2Config(\n",
        "            vocab_size=tokenizer.vocab_size,\n",
        "            n_positions=512,\n",
        "            n_ctx=512,\n",
        "            n_embd=512,\n",
        "            n_layer=4,\n",
        "            n_head=4,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            use_cache=False,\n",
        "        )\n",
        "model = TFGPT2LMHeadModel(config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "model.compile(optimizer=optimizer, loss=[loss, *[None] * model.config.n_layer], metrics=[metric])\n",
        "model.fit(dataset, epochs=100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
            "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
            "current_policy: <PolicyV1 \"mixed_float16\", loss_scale=DynamicLossScale(current_loss_scale=32768.0, num_good_steps=0, initial_loss_scale=32768.0, increment_period=2000, multiplier=2.0)>\n",
            "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
            "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa97b33aec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa97b33aec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fa996becc20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7fa996becc20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "6/6 [==============================] - 49s 442ms/step - loss: 10.5922 - accuracy: 0.0294\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 3s 445ms/step - loss: 9.7974 - accuracy: 0.0781\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 3s 447ms/step - loss: 9.4078 - accuracy: 0.0786\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 9.0169 - accuracy: 0.1165\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 8.5138 - accuracy: 0.2169\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 3s 452ms/step - loss: 7.9683 - accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 3s 452ms/step - loss: 7.4077 - accuracy: 0.4327\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 3s 454ms/step - loss: 6.8792 - accuracy: 0.4937\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 3s 455ms/step - loss: 6.4030 - accuracy: 0.5516\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 3s 456ms/step - loss: 5.9803 - accuracy: 0.6093\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 3s 461ms/step - loss: 5.6006 - accuracy: 0.6531\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 3s 463ms/step - loss: 5.2593 - accuracy: 0.6836\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 3s 459ms/step - loss: 4.9552 - accuracy: 0.7006\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 3s 463ms/step - loss: 4.6699 - accuracy: 0.7121\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 3s 458ms/step - loss: 4.4067 - accuracy: 0.7179\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 3s 459ms/step - loss: 4.1586 - accuracy: 0.7237\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 3s 454ms/step - loss: 3.9303 - accuracy: 0.7264\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 3s 456ms/step - loss: 3.7146 - accuracy: 0.7287\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 3s 453ms/step - loss: 3.5078 - accuracy: 0.7305\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 3s 452ms/step - loss: 3.3146 - accuracy: 0.7317\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 3.1277 - accuracy: 0.7326\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 2.9503 - accuracy: 0.7331\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 3s 450ms/step - loss: 2.7794 - accuracy: 0.7335\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 2.6134 - accuracy: 0.7337\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 2.4565 - accuracy: 0.7337\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 2.3034 - accuracy: 0.7338\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 2.1594 - accuracy: 0.7338\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 3s 446ms/step - loss: 2.0156 - accuracy: 0.7339\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 1.8817 - accuracy: 0.7339\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 1.7470 - accuracy: 0.7339\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 3s 447ms/step - loss: 1.6178 - accuracy: 0.7339\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 1.4951 - accuracy: 0.7338\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 3s 447ms/step - loss: 1.3766 - accuracy: 0.7339\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 1.2640 - accuracy: 0.7339\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 1.1555 - accuracy: 0.7339\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 3s 447ms/step - loss: 1.0530 - accuracy: 0.7339\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 3s 450ms/step - loss: 0.9544 - accuracy: 0.7339\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 3s 450ms/step - loss: 0.8634 - accuracy: 0.7338\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.7794 - accuracy: 0.7339\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 3s 453ms/step - loss: 0.7049 - accuracy: 0.7339\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.6380 - accuracy: 0.7338\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.5792 - accuracy: 0.7339\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 3s 453ms/step - loss: 0.5275 - accuracy: 0.7339\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.4823 - accuracy: 0.7339\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 3s 453ms/step - loss: 0.4416 - accuracy: 0.7339\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 3s 452ms/step - loss: 0.4056 - accuracy: 0.7339\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 3s 452ms/step - loss: 0.3733 - accuracy: 0.7339\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.3453 - accuracy: 0.7339\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 3s 456ms/step - loss: 0.3206 - accuracy: 0.7339\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.2987 - accuracy: 0.7339\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 3s 452ms/step - loss: 0.2786 - accuracy: 0.7339\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 3s 452ms/step - loss: 0.2605 - accuracy: 0.7339\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 3s 452ms/step - loss: 0.2442 - accuracy: 0.7338\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 3s 453ms/step - loss: 0.2299 - accuracy: 0.7339\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.2170 - accuracy: 0.7339\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 3s 450ms/step - loss: 0.2047 - accuracy: 0.7339\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.1942 - accuracy: 0.7339\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.1838 - accuracy: 0.7339\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 3s 452ms/step - loss: 0.1749 - accuracy: 0.7339\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 3s 447ms/step - loss: 0.1669 - accuracy: 0.7338\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.1589 - accuracy: 0.7339\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.1516 - accuracy: 0.7339\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.1454 - accuracy: 0.7339\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.1393 - accuracy: 0.7339\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.1336 - accuracy: 0.7339\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 3s 446ms/step - loss: 0.1279 - accuracy: 0.7339\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.1235 - accuracy: 0.7339\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 3s 453ms/step - loss: 0.1189 - accuracy: 0.7339\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 3s 447ms/step - loss: 0.1144 - accuracy: 0.7339\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.1104 - accuracy: 0.7339\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.1067 - accuracy: 0.7339\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 3s 450ms/step - loss: 0.1031 - accuracy: 0.7339\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 3s 450ms/step - loss: 0.0996 - accuracy: 0.7339\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 3s 447ms/step - loss: 0.0965 - accuracy: 0.7339\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.0938 - accuracy: 0.7339\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.0907 - accuracy: 0.7339\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.0879 - accuracy: 0.7339\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 3s 450ms/step - loss: 0.0853 - accuracy: 0.7339\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.0829 - accuracy: 0.7339\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.0805 - accuracy: 0.7339\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.0784 - accuracy: 0.7339\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 3s 450ms/step - loss: 0.0762 - accuracy: 0.7339\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.0742 - accuracy: 0.7339\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.0722 - accuracy: 0.7339\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.0703 - accuracy: 0.7339\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 3s 451ms/step - loss: 0.0686 - accuracy: 0.7339\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 3s 450ms/step - loss: 0.0669 - accuracy: 0.7339\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 3s 450ms/step - loss: 0.0654 - accuracy: 0.7339\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.0638 - accuracy: 0.7339\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.0622 - accuracy: 0.7339\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.0609 - accuracy: 0.7339\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.0595 - accuracy: 0.7339\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.0581 - accuracy: 0.7339\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 3s 447ms/step - loss: 0.0568 - accuracy: 0.7339\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 3s 450ms/step - loss: 0.0558 - accuracy: 0.7338\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.0545 - accuracy: 0.7339\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 3s 446ms/step - loss: 0.0533 - accuracy: 0.7339\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 3s 449ms/step - loss: 0.0524 - accuracy: 0.7339\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 3s 447ms/step - loss: 0.0512 - accuracy: 0.7339\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 3s 448ms/step - loss: 0.0503 - accuracy: 0.7339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa9305afc10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVnKp6TB3AJI"
      },
      "source": [
        "!pip install https://github.com/mymusise/transformers/archive/fix_mixed_precision4gpt2.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eau9SymJ4LF2",
        "outputId": "578c4299-b8a2-4c71-d879-4e14407f436e"
      },
      "source": [
        "#@title mixed_precision after train\n",
        "\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel, GPT2Config\n",
        "from tensorflow.keras.mixed_precision import experimental, global_policy\n",
        "\n",
        "\n",
        "policy = experimental.Policy('mixed_float16')\n",
        "experimental.set_policy(policy)\n",
        "current_policy = global_policy()\n",
        "print(f\"current_policy: {current_policy}\")\n",
        "\n",
        "\n",
        "config = GPT2Config(\n",
        "            vocab_size=tokenizer.vocab_size,\n",
        "            n_positions=512,\n",
        "            n_ctx=512,\n",
        "            n_embd=512,\n",
        "            n_layer=4,\n",
        "            n_head=4,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            use_cache=False,\n",
        "        )\n",
        "model = TFGPT2LMHeadModel(config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "model.compile(optimizer=optimizer, loss=[loss, *[None] * model.config.n_layer], metrics=[metric])\n",
        "model.fit(dataset, epochs=20)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
            "  Tesla K80, compute capability 3.7\n",
            "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
            "current_policy: <PolicyV1 \"mixed_float16\", loss_scale=DynamicLossScale(current_loss_scale=32768.0, num_good_steps=0, initial_loss_scale=32768.0, increment_period=2000, multiplier=2.0)>\n",
            "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
            "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
            "\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fea079d4ec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fea079d4ec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fea23286c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7fea23286c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convertWARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "6/6 [==============================] - 59s 2s/step - loss: 10.5825 - accuracy: 0.0305\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 9.7798 - accuracy: 0.0813\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 9.4015 - accuracy: 0.0863\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 9.0140 - accuracy: 0.1259\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 8.5197 - accuracy: 0.2167\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 7.9820 - accuracy: 0.3299\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 7.4249 - accuracy: 0.4427\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 6.9011 - accuracy: 0.5430\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 6.4375 - accuracy: 0.6279\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 6.0271 - accuracy: 0.7055\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 5.6643 - accuracy: 0.7885\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 5.3339 - accuracy: 0.8529\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 5.0323 - accuracy: 0.9020\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 4.7540 - accuracy: 0.9327\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 4.4923 - accuracy: 0.9497\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 4.2491 - accuracy: 0.9646\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 4.0191 - accuracy: 0.9744\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 3.8010 - accuracy: 0.9819\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 3.5975 - accuracy: 0.9866\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 11s 2s/step - loss: 3.3968 - accuracy: 0.9904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9c82ab790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    }
  ]
}
